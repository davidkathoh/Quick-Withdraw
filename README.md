# Quick-Withdraw

## About the idea

Mobile phones are replacing bank accounts in Africa thanks to the emergence of mobile money which has driven financial inclusion to the population that remains unbanked.

Even if people can send, receive or withdraw money instantly, the experience is still very hard mostly to illiterate and innumerate users; because mobile money users have to dial a USSD code then follow more than 5 steps to complete a transaction, if a mistake is made during the session lets say  the user entered a wrong beneficiary mobile number, he will have to cancel the session and restart the operation again from start. This becomes frustrating when mobile money users want to withdraw cash at mobile money kiosks, they have to wait a long queue before they get served because the process is too long that the mobile money agent is not able to serve his clients quickly, sometimes the agent also helps other clients to initiate the withdrawal process. My idea is to provide an Android App with a simplified and intuitive user experience which will allow users to scan the mobile money agent number visible on a display, leveraging the power of  text recognition or barcode scan of the vision ML Kit to extract the mobile money agent number then paste it at the required step during the withdraw process. This will allow mobile money agents to serve many users in a short period, it will also allow users to make transactions smoothly and fast.

# Plan on bringing the idea to life

The initial  version of the app has been already published on Google Play ([Eskke](https://play.google.com/store/apps/details?id=com.geekslab.david.mobilesms)) This uses Accessibility Services to simplify and visualize complex  USSD-based processes mostly for illiterate and innumerate users  so that they can  make transaction fast, the app has now more than 300  monthly active users and 100 downloads on google play, the plan now is to add a feature that will allow the users to withdraw money quickly, with the help of text recognition and barcode scan  of Vision ML Kit, that is why I would like google to :

- Guide  to make ML KIT  perfectly work offline  on low-end Android devices
- Provide mentorship about Machine learning and experience different user case on mobile devices.
- Showcase the application on google play

## Timeline

1. **December 2018 - January 2019:** Learn deeply about Machine learning Kit
2. **February 2020:** Implementation of  text recognition and barcode scanning from the Vision ML Kit
3. **March 2020:** Run App's beta test
4. **April 2020:** Fix bugs received from test feedback and deploy the app on Google play

## About me

I am an Android developer based in Goma, in the Democratic Republic of Congo passionate about building user-centred and useful apps, last year I participated in the Google Africa Scholarship facilitated by Andela this equipped me with the knowledge of building  android apps following the industry standard, this year again i am in the  same program now as a mentor. I am also driven by the desire of sharing knowledge and making it accessible to as many people as possible, I am doing so by translating English tutorials into French ([blog](https://medium.com/@davidkathoh)) and speaking at GDG meetups.

